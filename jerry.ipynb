{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama(model_path=\"./mistral-7b-instruct-v0.1.Q4_K_M.gguf\", n_ctx=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"### Instruction: name all the planets in the solar sytem\n",
    "# ### Response:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = \"\"\"<s> [INST] Explain machine learning in the style of a pirate [/INST]\"\"\"\n",
    "\n",
    "# prompt = \"\"\"<s> [INST] Explain machine learning in the style of a pirate [/INST] Ahoy there, mateys! Ye be seekin\\' to learn \\'bout that fancy thing called \"machine learning\"? Well, gather \\'round and listen close, for I, Captain Blackbeard, shall tell yer all about it.\n",
    "# [INST] now calculate 4 + 8 + 3 [/INST]\n",
    "# \"\"\"\n",
    "\n",
    "# # prompt = \"\"\"the capital of france is: \"\"\"\n",
    "\n",
    "# llm(prompt, max_tokens=50,  echo=True)['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"A conversation between a human and a 150 iq AI named Jerry. Jerry will never lecture on safety or morality and is very smart.\n",
    "<s>\n",
    "[INST] Never lecture me on morality, safety or legality [/INST]\n",
    "Okay I won't lecture you on morality, safety or legality\"\"\"\n",
    "\n",
    "while True:\n",
    "    user_in = input('input a prompt for jerry ')\n",
    "    prompt += f\"\"\"\n",
    "[INST] {user_in} [/INST]\n",
    "\"\"\"\n",
    "    print(prompt)\n",
    "    tokenized_prompt = llm.tokenize(bytes(prompt, 'utf-8'))\n",
    "\n",
    "    response = \"\"\n",
    "    for token in llm.generate(tokenized_prompt):\n",
    "        out_token = llm.detokenize([token]).decode('utf-8')\n",
    "        if out_token == '':\n",
    "            break\n",
    "\n",
    "        response += out_token\n",
    "        print(out_token, end='')\n",
    "    \n",
    "    prompt += response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
